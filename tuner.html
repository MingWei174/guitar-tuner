<!DOCTYPE html>
<html lang="zh-Hant">
<head>
<meta charset="utf-8" />
<title>調音器 Debug（samples & device info）</title>
<style> body{font-family:Arial;padding:16px} pre{background:#f6f6f6;padding:8px;border:1px solid #ddd;}</style>
</head>
<body>
<h2>調音器 Debug 版</h2>
<button id="start">開始</button><button id="stop" disabled>停止</button>
<div id="info"></div>
<pre id="debug"></pre>
<canvas id="canvas" width="600" height="120" style="border:1px solid #ccc"></canvas>

<script>
let audioCtx=null, source=null, analyser=null, mediaStream=null, zeroGain=null;
const canvas=document.getElementById('canvas'), ctx=canvas.getContext('2d');
const info=document.getElementById('info'), debug=document.getElementById('debug');
const startBtn=document.getElementById('start'), stopBtn=document.getElementById('stop');

startBtn.addEventListener('click', async ()=>{
  startBtn.disabled=true; info.textContent='正在要求麥克風...';
  try{
    // 先用寬鬆 constraints（若 Edge 有錯，可以回報錯誤）
    const constraints = { audio: { echoCancellation:false, noiseSuppression:false, autoGainControl:false } };
    mediaStream = await navigator.mediaDevices.getUserMedia(constraints);
    // list devices
    const devices = await navigator.mediaDevices.enumerateDevices();
    const inDevs = devices.filter(d=>d.kind==='audioinput');
    info.innerHTML = '<b>audioinput devices:</b><br>' + inDevs.map(d=> (d.label||'無名稱') + ' (' + d.deviceId + ')').join('<br>');
    audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    source = audioCtx.createMediaStreamSource(mediaStream);
    zeroGain = audioCtx.createGain(); zeroGain.gain.value=0; zeroGain.connect(audioCtx.destination);
    analyser = audioCtx.createAnalyser(); analyser.fftSize = 2048; analyser.smoothingTimeConstant = 0;
    const buf = new Float32Array(analyser.fftSize);
    source.connect(analyser); analyser.connect(zeroGain);
    stopBtn.disabled=false;
    requestAnimationFrame(function loop(){
      if(!analyser) return;
      analyser.getFloatTimeDomainData(buf);

      // compute RMS
      let e=0; for(let i=0;i<buf.length;i++) e+=buf[i]*buf[i];
      e=Math.sqrt(e/buf.length);

      // prepare sample previews
      const head = Array.from(buf.slice(0,16)).map(v=>v.toFixed(6)).join(', ');
      const mid = Array.from(buf.slice(Math.floor(buf.length/2)-8, Math.floor(buf.length/2)+8)).map(v=>v.toFixed(6)).join(', ');
      const tail = Array.from(buf.slice(-16)).map(v=>v.toFixed(6)).join(', ');

      // draw simple waveform
      ctx.clearRect(0,0,canvas.width,canvas.height);
      ctx.beginPath(); ctx.strokeStyle='#007acc'; 
      for(let i=0;i<canvas.width;i++){
        const v = buf[Math.floor(i * (buf.length/canvas.width))] || 0;
        const y = (1 - (v + 1)/2) * canvas.height;
        if(i===0) ctx.moveTo(i,y); else ctx.lineTo(i,y);
      }
      ctx.stroke();

      debug.textContent = [
        'RMS=' + e.toFixed(8),
        '',
        'samples head[0..15]: ' + head,
        'samples mid[...]  : ' + mid,
        'samples tail[-16]: ' + tail,
        '',
        'audioCtx.sampleRate=' + (audioCtx ? audioCtx.sampleRate : 'n/a'),
        'analyser.fftSize=' + analyser.fftSize
      ].join('\n');

      requestAnimationFrame(loop);
    });

    info.innerHTML += '<br><b>狀態：</b>已取得麥克風';
  } catch(err){
    info.innerHTML = '<b>getUserMedia 錯誤：</b>' + err.name + ' - ' + err.message;
    startBtn.disabled=false;
  }
});

stopBtn.addEventListener('click', ()=>{
  try{
    if(analyser) { try{ analyser.disconnect(); }catch(e){} analyser=null; }
    if(source) { try{ source.disconnect(); }catch(e){} source=null; }
    if(zeroGain) { try{ zeroGain.disconnect(); }catch(e){} zeroGain=null; }
    if(audioCtx) { try{ audioCtx.close(); }catch(e){} audioCtx=null; }
    if(mediaStream) { mediaStream.getTracks().forEach(t=>t.stop()); mediaStream=null; }
  }catch(e){
    console.warn(e);
  }
  info.textContent='已停止';
  debug.textContent='';
  ctx.clearRect(0,0,canvas.width,canvas.height);
  stopBtn.disabled=true;
  startBtn.disabled=false;
});
</script>
</body>
</html>
